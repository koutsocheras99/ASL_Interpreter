### ***This project is a American Sign Language Interpreter implemented with OpenCV and Keras.***

<br>

The DataSet was created by me and it consists of 16200 images.
  
  - 600 for each gesture tottaly.
    - 500 for training
    - 50 for testing
    - 50 for validating
    
<br>

Unfortunately due to size of the dataset ( >400MB) I haven't been able to upload it.

<br>
    
Every image has been going through blurring (Median and Gaussian) and  the [Canny Method](https://en.wikipedia.org/wiki/Canny_edge_detector) has been used to minimize the loss.
  
<br>

A image sample from the dataset and specifically for the letter R is:
<br>
![R (9)](https://user-images.githubusercontent.com/37080724/77018348-dac2fc80-6985-11ea-966e-a0ff06c23706.jpg)

<br>
The sequential CNN that was trained is shown below:
<br>

![image](https://user-images.githubusercontent.com/37080724/77018568-9e43d080-6986-11ea-9a07-5c5beb899bc5.png)

<br>

*A fully functional demo will be uploaded soon!*

